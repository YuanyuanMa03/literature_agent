# ğŸš€ å¿«é€Ÿå…¥é—¨æŒ‡å—

## ğŸ“‹ ç›®å½•
- [å®‰è£…æŒ‡å—](#å®‰è£…æŒ‡å—)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [ä½¿ç”¨ç¤ºä¾‹](#ä½¿ç”¨ç¤ºä¾‹)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸ”§ å®‰è£…æŒ‡å—

### æ–¹å¼ä¸€ï¼šè‡ªåŠ¨å®‰è£…ï¼ˆæ¨èï¼‰
```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/yourusername/literature_agent.git
cd literature_agent

# è¿è¡Œå®‰è£…è„šæœ¬
chmod +x setup.sh
./setup.sh
```

### æ–¹å¼äºŒï¼šæ‰‹åŠ¨å®‰è£…
```bash
# 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate  # Linux/macOS
# æˆ– venv\Scripts\activate  # Windows

# 2. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 3. é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘.envæ–‡ä»¶ï¼Œå¡«å…¥APIä¿¡æ¯
```

### æ–¹å¼ä¸‰ï¼špipå®‰è£…
```bash
# ä»æºç å®‰è£…
pip install -e .

# æˆ–ä»PyPIå®‰è£…ï¼ˆå¦‚æœå·²å‘å¸ƒï¼‰
pip install literature-agent-system
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. é…ç½®API
ç¼–è¾‘`.env`æ–‡ä»¶ï¼š
```env
# APIé…ç½®
OPENAI_API_BASE=https://api.siliconflow.cn/v1
OPENAI_API_KEY=your-api-key-here
LLM_MODEL=Qwen/Qwen3-Omni-30B-A3B-Instruct
```

### 2. å‡†å¤‡æ•°æ®
æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼š
- Web of Scienceå¯¼å‡ºæ–‡ä»¶ï¼ˆåˆ†æ®µæ–‡ä»¶ï¼‰
- Excelæ–‡ä»¶ï¼ˆ.xlsx, .xlsï¼‰
- CSVæ–‡ä»¶

### 3. è¿è¡Œç¨‹åº
```bash
# å®Œæ•´æµç¨‹ï¼ˆæ¨èï¼‰
python main.py

# ä»…æ•°æ®é¢„å¤„ç†
python demo_data_preprocessing.py

# PDFæ·±åº¦åˆ†æ
python main_stage2.py
```

---

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šå¤„ç†WOSæ•°æ®
```python
from agents.data_preprocessing_agent import preprocess_wos_data

# è‡ªåŠ¨æ£€æµ‹å¹¶å¤„ç†WOSåˆ†æ®µæ–‡ä»¶
result = preprocess_wos_data(
    input_source="auto",
    output_dir="data",
    output_filename="processed_literature.csv"
)

if result["success"]:
    print(f"å¤„ç†æˆåŠŸ: {result['total_records']} ç¯‡æ–‡çŒ®")
    print(f"è¾“å‡ºæ–‡ä»¶: {result['output_file']}")
```

### ç¤ºä¾‹2ï¼šå®Œæ•´åˆ†ææµç¨‹
```python
from main import LiteratureResearchSystem

# åˆ›å»ºç³»ç»Ÿå®ä¾‹
system = LiteratureResearchSystem()

# è¿è¡Œå®Œæ•´æµç¨‹
df, report = system.run_research(
    research_topic="åœŸå£¤æœ‰æœºç¢³é¥±å’Œæœºåˆ¶",
    test_mode=True,  # æµ‹è¯•æ¨¡å¼ï¼Œåªå¤„ç†10ç¯‡
    test_size=10,
    analyze_top=5
)

print(f"åˆ†æå®Œæˆï¼Œå¤„ç†äº† {len(df)} ç¯‡æ–‡çŒ®")
```

### ç¤ºä¾‹3ï¼šè‡ªå®šä¹‰ç­›é€‰æ ‡å‡†
```python
from agents.screening_agent import LiteratureScreeningAgent
from core.llm import LiteratureLLM

# åˆ›å»ºLLMå’ŒAgent
llm = LiteratureLLM()
agent = LiteratureScreeningAgent(llm)

# è‡ªå®šä¹‰ç­›é€‰æç¤º
custom_prompt = """
è¯·åˆ¤æ–­ä»¥ä¸‹æ–‡çŒ®æ˜¯å¦åŒ…å«å…³äºã€æ°”å€™å˜åŒ–å¯¹å†œä¸šå½±å“ã€‘çš„æ•°æ®ã€‚

è¯„åˆ¤æ ‡å‡†ï¼š
1. å¿…é¡»åŒ…å«å®éªŒæ•°æ®æˆ–è°ƒæŸ¥æ•°æ®
2. ç ”ç©¶å¯¹è±¡ä¸ºå†œä¸šç³»ç»Ÿ
3. ç ”ç©¶æ–¹æ³•åŒ…æ‹¬å®šé‡åˆ†æ
"""

# è¿è¡Œç­›é€‰
df_filtered = agent.run(df, custom_prompt=custom_prompt)
```

### ç¤ºä¾‹4ï¼šæ‰¹é‡å¤„ç†PDF
```python
from agents.deep_analysis_agent import DeepAnalysisAgent

# åˆ›å»ºæ·±åº¦åˆ†æAgent
agent = DeepAnalysisAgent(llm)

# æ‰¹é‡åˆ†æPDF
result = agent.run(
    pdf_directory="pdfs/",
    output_dir="data/results/",
    extract_tables=True,
    extract_figures=True
)
```

---

## ğŸ“Š è¾“å‡ºæ–‡ä»¶è¯´æ˜

### æ•°æ®é¢„å¤„ç†é˜¶æ®µ
- `literature_data_processed.csv` - æ ‡å‡†åŒ–çš„æ–‡çŒ®æ•°æ®
- `literature_data_processed.xlsx` - Excelæ ¼å¼çš„æ–‡çŒ®æ•°æ®

### ç­›é€‰åˆ†æé˜¶æ®µ
- `literature_screening_results.xlsx` - ç­›é€‰ç»“æœ
- `literature_analysis_results.xlsx` - åˆ†ææ•°æ®
- `literature_research_report.md` - ç ”ç©¶æŠ¥å‘Š

### PDFæ·±åº¦åˆ†æé˜¶æ®µ
- `deep_analysis_results.xlsx` - æ·±åº¦åˆ†æç»“æœ
- `deep_analysis_results.json` - è¯¦ç»†JSONæ•°æ®
- `extracted_tables/` - æå–çš„è¡¨æ ¼
- `extracted_figures/` - æå–çš„å›¾è¡¨

---

## â“ å¸¸è§é—®é¢˜

### Q1: APIé…ç½®é—®é¢˜
**é—®é¢˜**: æç¤º"éœ€è¦æä¾›APIå¯†é’¥"
**è§£å†³**: 
1. æ£€æŸ¥`.env`æ–‡ä»¶æ˜¯å¦å­˜åœ¨
2. ç¡®ä¿`OPENAI_API_KEY`å·²æ­£ç¡®å¡«å†™
3. éªŒè¯APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ

### Q2: PDFå¤„ç†å¤±è´¥
**é—®é¢˜**: PDFè½¬æ¢æŠ¥é”™
**è§£å†³**:
1. å®‰è£…poppler-utilsï¼š
   - macOS: `brew install poppler`
   - Ubuntu: `sudo apt-get install poppler-utils`
2. æ£€æŸ¥PDFæ–‡ä»¶æ˜¯å¦æŸå

### Q3: å†…å­˜ä¸è¶³
**é—®é¢˜**: å¤„ç†å¤§é‡æ–‡çŒ®æ—¶å†…å­˜ä¸è¶³
**è§£å†³**:
1. ä½¿ç”¨æµ‹è¯•æ¨¡å¼ï¼š`test_mode=True`
2. åˆ†æ‰¹å¤„ç†ï¼šè®¾ç½®`test_size`
3. å¢åŠ ç³»ç»Ÿå†…å­˜æˆ–ä½¿ç”¨æ›´å¼ºå¤§çš„æœºå™¨

### Q4: ç½‘ç»œè¿æ¥é—®é¢˜
**é—®é¢˜**: APIè°ƒç”¨è¶…æ—¶
**è§£å†³**:
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. ä½¿ç”¨ä»£ç†æˆ–VPN
3. è°ƒæ•´APIè¶…æ—¶è®¾ç½®

### Q5: æ•°æ®æ ¼å¼é—®é¢˜
**é—®é¢˜**: æ–‡çŒ®æ•°æ®è¯»å–å¤±è´¥
**è§£å†³**:
1. ç¡®ä¿æ–‡ä»¶åŒ…å«å¿…éœ€çš„åˆ—ï¼ˆæ ‡é¢˜ã€æ‘˜è¦ï¼‰
2. æ£€æŸ¥æ–‡ä»¶ç¼–ç ï¼ˆå»ºè®®UTF-8ï¼‰
3. ä½¿ç”¨æ•°æ®é¢„å¤„ç†Agentè¿›è¡Œæ ¼å¼è½¬æ¢

---

## ğŸ”§ é«˜çº§é…ç½®

### è‡ªå®šä¹‰LLMæ¨¡å‹
```python
# åœ¨.envæ–‡ä»¶ä¸­é…ç½®
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=2000
```

### æ‰¹é‡å¤„ç†é…ç½®
```python
# åœ¨main.pyä¸­è°ƒæ•´å‚æ•°
system.run_research(
    test_mode=False,  # å…³é—­æµ‹è¯•æ¨¡å¼
    test_size=0,      # å¤„ç†æ‰€æœ‰æ–‡çŒ®
    analyze_top=100,  # åˆ†æå‰100ç¯‡
    enable_planning=False  # è·³è¿‡è§„åˆ’é˜¶æ®µ
)
```

### è¿›åº¦è¿½è¸ª
```python
# å¯ç”¨è¯¦ç»†è¿›åº¦è¿½è¸ª
system = LiteratureResearchSystem(
    enable_progress_tracking=True
)
```

---

## ğŸ“š æ›´å¤šæ–‡æ¡£

- [å®Œæ•´APIæ–‡æ¡£](docs/api.md)
- [Agentå¼€å‘æŒ‡å—](docs/agent_development.md)
- [éƒ¨ç½²æŒ‡å—](docs/deployment.md)
- [æ•…éšœæ’é™¤](docs/troubleshooting.md)

---

## ğŸ†˜ è·å–å¸®åŠ©

- ğŸ“– æŸ¥çœ‹[README.md](README.md)
- ğŸ› æäº¤[Issue](https://github.com/yourusername/literature_agent/issues)
- ğŸ’¬ åŠ å…¥è®¨è®ºç¾¤
- ğŸ“§ è”ç³»å¼€å‘å›¢é˜Ÿ