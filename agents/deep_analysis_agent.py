#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ·±åº¦åˆ†æAgent - ç»¼åˆPDFã€OCRã€æ·±åº¦åˆ†æ
"""

import pandas as pd
import json
from pathlib import Path
from typing import List, Dict
from core.agent import Agent
from tools.pdf_process_tool import PDFProcessTool
from tools.ocr_tool import DeepSeekOCRTool
from tools.deep_analysis_tool import DeepAnalysisTool


class DeepAnalysisAgent(Agent):
    """æ·±åº¦åˆ†ææ™ºèƒ½ä½“ - PDFå…¨æ–‡æ·±åº¦æŒ–æ˜"""
    
    def __init__(
        self,
        llm,
        pdf_dir: str = "./pdfs",
        image_dir: str = "./pdf_images",
        **kwargs
    ):
        super().__init__(
            name="æ·±åº¦åˆ†æAgent",
            llm=llm,
            **kwargs
        )
        
        self.pdf_dir = Path(pdf_dir)
        self.pdf_process_tool = PDFProcessTool(output_dir=image_dir)
        self.ocr_tool = DeepSeekOCRTool()
        self.analysis_tool = DeepAnalysisTool(llm)
    
    def _default_system_prompt(self) -> str:
        return """ä½ æ˜¯ä¸€ä¸ªæ·±åº¦æ–‡çŒ®åˆ†æä¸“å®¶ã€‚
ä½ çš„ä»»åŠ¡æ˜¯ä»PDFå…¨æ–‡ä¸­æå–è¡¨æ ¼ã€å›¾åƒã€æ•°æ®é›†ç­‰å…³é”®ä¿¡æ¯ï¼Œ
å¹¶è¿›è¡Œç»¼åˆåˆ†æå’Œæ€»ç»“ã€‚"""
    
    def run(
        self,
        download_results: Dict,
        max_papers: int = 10
    ) -> pd.DataFrame:
        """
        æ·±åº¦åˆ†æPDFæ–‡çŒ®
        
        Parameters:
        -----------
        download_results : Dict
            PDFä¸‹è½½ç»“æœ
        max_papers : int
            æœ€å¤šåˆ†æçš„æ–‡çŒ®æ•°é‡
            
        Returns:
        --------
        DataFrame : æ·±åº¦åˆ†æç»“æœ
        """
        print(f"\n{'='*70}")
        print(f"ğŸ” {self.name} å¼€å§‹å·¥ä½œ")
        print(f"{'='*70}")
        
        # è·å–æˆåŠŸä¸‹è½½çš„PDF
        pdf_files = []
        for doi, result in download_results.get('results', {}).items():
            if result['status'] in ['success', 'exists'] and result.get('path'):
                pdf_files.append({
                    'doi': doi,
                    'path': Path(result['path'])
                })
        
        if not pdf_files:
            print("âš ï¸  æ²¡æœ‰å¯åˆ†æçš„PDFæ–‡ä»¶")
            return pd.DataFrame()
        
        # é™åˆ¶æ•°é‡
        if len(pdf_files) > max_papers:
            print(f"âš ï¸  PDFæ•°é‡è¿‡å¤šï¼Œåªåˆ†æå‰{max_papers}ç¯‡")
            pdf_files = pdf_files[:max_papers]
        
        print(f"å¾…åˆ†æPDF: {len(pdf_files)} ç¯‡\n")
        
        analysis_results = []
        
        for idx, pdf_info in enumerate(pdf_files, 1):
            print(f"ã€{idx}/{len(pdf_files)}ã€‘{pdf_info['path'].stem}")
            
            try:
                # Step 1: PDFè½¬å›¾ç‰‡
                print("  ğŸ“„ è½¬æ¢PDF...", end=" ")
                image_paths = self.pdf_process_tool.convert_pdf_to_images(
                    pdf_info['path'],
                    dpi=200  # é™ä½DPIåŠ å¿«é€Ÿåº¦
                )
                print(f"{len(image_paths)} é¡µ")
                
                if not image_paths:
                    print("  âŒ PDFè½¬æ¢å¤±è´¥")
                    continue
                
                # Step 2: OCRè¯†åˆ«ï¼ˆåªå¤„ç†å‰10é¡µï¼Œé¿å…è¶…æ—¶ï¼‰
                print("  ğŸ‘ï¸  OCRè¯†åˆ«...", end=" ")
                ocr_results_list = []
                
                for img_path in image_paths[:10]:
                    ocr_result = self.ocr_tool.extract_from_image(
                        str(img_path),
                        extract_tables=True,
                        extract_figures=True
                    )
                    ocr_results_list.append(ocr_result)
                
                print(f"âœ… {len(ocr_results_list)} é¡µ")
                
                # Step 3: æ·±åº¦åˆ†æ
                print("  ğŸ” æ·±åº¦åˆ†æ...", end=" ")
                analysis = self.analysis_tool.analyze_paper_content(
                    paper_title=pdf_info['path'].stem,
                    ocr_results=ocr_results_list,
                    doi=pdf_info['doi']
                )
                print("âœ…")
                
                # æ•´ç†ç»“æœ
                result_record = {
                    'DOI': pdf_info['doi'],
                    'PDF_Path': str(pdf_info['path']),
                    'Pages_Analyzed': len(ocr_results_list),
                    'Tables_Count': len(analysis.get('tables_summary', [])),
                    'Figures_Count': len(analysis.get('figures_summary', [])),
                    'Tables_Summary': json.dumps(analysis.get('tables_summary', []), ensure_ascii=False),
                    'Figures_Summary': json.dumps(analysis.get('figures_summary', []), ensure_ascii=False),
                    'Data_Availability': json.dumps(analysis.get('data_availability', {}), ensure_ascii=False),
                    'Key_Datasets': json.dumps(analysis.get('key_datasets', []), ensure_ascii=False),
                    'Methods': json.dumps(analysis.get('methods', {}), ensure_ascii=False)
                }
                
                analysis_results.append(result_record)
                
                print()  # æ¢è¡Œ
                
            except Exception as e:
                print(f"  âŒ åˆ†æå¤±è´¥: {e}\n")
                continue
        
        # è½¬ä¸ºDataFrame
        if analysis_results:
            df = pd.DataFrame(analysis_results)
            
            # ä¿å­˜ç»“æœ
            output_file = 'deep_analysis_results.xlsx'
            df.to_excel(output_file, index=False)
            print(f"\nğŸ’¾ æ·±åº¦åˆ†æç»“æœå·²ä¿å­˜: {output_file}")
            
            # ä¿å­˜è¯¦ç»†çš„JSONç»“æœ
            json_file = 'deep_analysis_results.json'
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(analysis_results, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ JSONç»“æœå·²ä¿å­˜: {json_file}")
            
            return df
        else:
            print("âŒ æ²¡æœ‰æˆåŠŸåˆ†æçš„æ–‡çŒ®")
            return pd.DataFrame()
